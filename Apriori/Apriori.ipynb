{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关联分析\n",
    "\n",
    "关联分析：从大数据集中寻找物品间的隐含关系\n",
    "频繁项集：经常出现在一起的物品集合\n",
    "关联规则：暗示两种物品之间可能存在很强的关系\n",
    "频繁的衡量尺度：\n",
    "* 支持度：数据集中包含该项集记录所占比例\n",
    "* 置信度：如{尿布}->{葡萄酒}的置信度为 `r = 支持度({尿布，葡萄酒}) / 支持度({尿布})`，\n",
    "意味着对于包含{尿布}的记录，对其中的r * 记录数都适用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要想找到支持度大于0.8的项集，我们就需要对所有的物品进行排列组合得到所有可能的项集，再进行支持度的计算。\n",
    "这会十分耗时低效，我们将分析Apriori原理，该原理可以减小关联学习的计算量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori原理\n",
    ">a priori —— 一个先验。在拉丁语中指“来自以前”。我们在贝叶斯统计时经常使用先验知识作为判断的条件，这些知识来自领域的知识，先前的测量结果等等。\n",
    "\n",
    "原理内容：如果某个项集是频繁的，那么它所有的子集也是频繁的。同理，如果某个项集是非频繁集，那么它的所有超集也是非频繁的。\n",
    "\n",
    "利用此原理可有效降低项集的指数级增长"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用Apriori发现频繁集\n",
    "算法描述：\n",
    "\n",
    "    生成所有单个物品的项集列表\n",
    "    对每个数据记录\n",
    "        对每个项集\n",
    "            包含该项集就增加总计数值\n",
    "    对每个项集的的总数/总数据记录数\n",
    "        如果满足最小支持度，则保留此项集\n",
    "    对剩下的项集组合以生成包含两个元素的项集\n",
    "    重复上述去除项集的操作，直到所有的项集删除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成候选项集\n",
    "* 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_c1(dataset):\n",
    "    c1 = []\n",
    "    for row in dataset:\n",
    "        for item in row:\n",
    "            if not [item] in c1:\n",
    "                c1.append([item])\n",
    "    c1.sort()\n",
    "    return list(map(frozenset, c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度（minSupport）的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(dataset, candidate, min_support):\n",
    "    sscnt = {}\n",
    "    for row in dataset:\n",
    "        for can in candidate:\n",
    "            if can.issubset(row):\n",
    "                if can not in sscnt:\n",
    "                    sscnt[can] = 1\n",
    "                else:\n",
    "                    sscnt[can] += 1\n",
    "    num = float(len(dataset))\n",
    "    retlist = []\n",
    "    support_data = {}\n",
    "    for key in sscnt:\n",
    "        support = sscnt[key]/num\n",
    "        if support >= min_support:\n",
    "            retlist.insert(0, key)\n",
    "        support_data[key] = support\n",
    "    return retlist, support_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[frozenset({1}), frozenset({2}), frozenset({3}), frozenset({4}), frozenset({5})]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_data()\n",
    "c1 = create_c1(dataset)\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1, 3, 4}, {2, 3, 5}, {1, 2, 3, 5}, {2, 5}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = list(map(set, dataset))\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用0.5作为最小支持度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1, supportdata0 = scan(D, c1, 0.5)\n",
    "L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现4被删除，说明4没有达到最小支持度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 组织完整Apriori算法\n",
    "    \n",
    "    当集合中的个数大于0时\n",
    "        构建一个k个项组成的候选项集的列表\n",
    "        检查数据以确认每个项集都是频繁的\n",
    "        保留频繁项集并构建k+1项组成的候选项集的列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在候选项集中生成新的项集，前k-2个项相同时，合并这两个项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_gen(Lk, k):\n",
    "    relist = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            L1 = list(Lk[i])[:k-2]\n",
    "            L2 = list(Lk[j])[:k-2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            if L1 == L2:\n",
    "                relist.append(Lk[i] | Lk[j])\n",
    "    return relist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造所有可能的集合并算出其支持度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(dataset, min_sup = 0.5):\n",
    "    c1 = create_c1(dataset)\n",
    "    d = list(map(set, dataset))\n",
    "    L1, sup_data = scan(d, c1, min_sup)  # 选择达到最小支持度的项集\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    while len(L[k-2]) > 0:\n",
    "        CK = apriori_gen(L[k-2], k)   # 建立大小为K的项集\n",
    "        Lk, supK = scan(dataset, CK, min_sup)  # 删选达到最小支持度的项集\n",
    "        sup_data.update(supK)  # 更新支持字典\n",
    "        L.append(Lk)        # 记录所有项集记录\n",
    "        k += 1\n",
    "    return L, sup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})],\n",
       "  [frozenset({2, 3}), frozenset({3, 5}), frozenset({2, 5}), frozenset({1, 3})],\n",
       "  [frozenset({2, 3, 5})],\n",
       "  []],\n",
       " {frozenset({1}): 0.5,\n",
       "  frozenset({3}): 0.75,\n",
       "  frozenset({4}): 0.25,\n",
       "  frozenset({2}): 0.75,\n",
       "  frozenset({5}): 0.75,\n",
       "  frozenset({1, 3}): 0.5,\n",
       "  frozenset({2, 5}): 0.75,\n",
       "  frozenset({3, 5}): 0.5,\n",
       "  frozenset({2, 3}): 0.5,\n",
       "  frozenset({1, 5}): 0.25,\n",
       "  frozenset({1, 2}): 0.25,\n",
       "  frozenset({2, 3, 5}): 0.5})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[frozenset({5}), frozenset({2}), frozenset({3})], [frozenset({2, 5})], []],\n",
       " {frozenset({1}): 0.5,\n",
       "  frozenset({3}): 0.75,\n",
       "  frozenset({4}): 0.25,\n",
       "  frozenset({2}): 0.75,\n",
       "  frozenset({5}): 0.75,\n",
       "  frozenset({2, 5}): 0.75,\n",
       "  frozenset({3, 5}): 0.5,\n",
       "  frozenset({2, 3}): 0.5})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori(dataset, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从频繁项中挖掘关联规则\n",
    "关联规则的量化方法：\n",
    "* 可信度：\n",
    "    一条规则P-->H的可信度定义为：\n",
    "        support(P | H) / support(P)\n",
    "        \n",
    "**假设0， 1， 2 ——> 3 并不满足最小可信度要求，那么任何左部为{0， 1， 2}的子集的规则也不会满足最小可信度要求**\n",
    "\n",
    "利用上述性质来减少需要测试的规则项目：\n",
    "* 分级法：\n",
    "    首先从一个频繁项开始，创建一个规则列表，此列表右部只有一个元素，然后对这些规则进行测试\n",
    "    然后合并所有剩余规则来创建一个新的规则列表，其中列表右部包含两个元素\n",
    "    重复上述过程，直到列表右部不再增加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成关联规则\n",
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    \"\"\"generateRules\n",
    "\n",
    "    Args:\n",
    "        L 频繁项集列表\n",
    "        supportData 频繁项集支持度的字典\n",
    "        minConf 最小置信度\n",
    "    Returns:\n",
    "        bigRuleList 可信度规则列表（关于 (A->B+置信度) 3个字段的组合）\n",
    "    \"\"\"\n",
    "    bigRuleList = []\n",
    "    # 假设 L = [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])], [frozenset([1, 3]), frozenset([2, 5]), frozenset([2, 3]), frozenset([3, 5])], [frozenset([2, 3, 5])]]\n",
    "    for i in range(1, len(L)):\n",
    "        # 获取频繁项集中每个组合的所有元素\n",
    "        for freqSet in L[i]:\n",
    "            # 假设: freqSet= frozenset([1, 3]), H1=[frozenset([1]), frozenset([3])]\n",
    "            # 组合总的元素并遍历子元素，并转化为 frozenset 集合，再存放到 list 列表中\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            # 2 个的组合，走 else, 2 个以上的组合，走 if\n",
    "            if (i > 1):\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算可信度（confidence）\n",
    "def calcConf(freqSet, H\n",
    ", supportData, brl, minConf=0.7):\n",
    "    \"\"\"calcConf（对两个元素的频繁项，计算可信度，例如:  {1,2}/{1} 或者 {1,2}/{2} 看是否满足条件）\n",
    "\n",
    "    Args:\n",
    "        freqSet 频繁项集中的元素，例如: frozenset([1, 3])    \n",
    "        H 频繁项集中的元素的集合，例如: [frozenset([1]), frozenset([3])]\n",
    "        supportData 所有元素的支持度的字典\n",
    "        brl 关联规则列表的空数组\n",
    "        minConf 最小可信度\n",
    "    Returns:\n",
    "        prunedH 记录 可信度大于阈值的集合\n",
    "    \"\"\"\n",
    "    # 记录可信度大于最小可信度（minConf）的集合\n",
    "    prunedH = []\n",
    "    for conseq in H: # 假设 freqSet = frozenset([1, 3]), H = [frozenset([1]), frozenset([3])]，那么现在需要求出 frozenset([1]) -> frozenset([3]) 的可信度和 frozenset([3]) -> frozenset([1]) 的可信度\n",
    "\n",
    "        print ('confData=', freqSet, H, conseq, freqSet-conseq)\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq] # 支持度定义: a -> b = support(a | b) / support(a). 假设  freqSet = frozenset([1, 3]), conseq = [frozenset([1])]，那么 frozenset([1]) 至 frozenset([3]) 的可信度为 = support(a | b) / support(a) = supportData[freqSet]/supportData[freqSet-conseq] = supportData[frozenset([1, 3])] / supportData[frozenset([1])]\n",
    "        if conf >= minConf:\n",
    "            # 只要买了 freqSet-conseq 集合，一定会买 conseq 集合（freqSet-conseq 集合和 conseq 集合是全集）\n",
    "            print(freqSet-conseq, '-->', conseq, 'conf:', conf)\n",
    "            brl.append((freqSet-conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 递归计算频繁项集的规则\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    \"\"\"rulesFromConseq\n",
    "\n",
    "    Args:\n",
    "        freqSet 频繁项集中的元素，例如: frozenset([2, 3, 5])    \n",
    "        H 频繁项集中的元素的集合，例如: [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "        supportData 所有元素的支持度的字典\n",
    "        brl 关联规则列表的数组\n",
    "        minConf 最小可信度\n",
    "    \"\"\"\n",
    "    # H[0] 是 freqSet 的元素组合的第一个元素，并且 H 中所有元素的长度都一样，长度由 aprioriGen(H, m+1) 这里的 m + 1 来控制\n",
    "    # 该函数递归时，H[0] 的长度从 1 开始增长 1 2 3 ...\n",
    "    # 假设 freqSet = frozenset([2, 3, 5]), H = [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "    # 那么 m = len(H[0]) 的递归的值依次为 1 2\n",
    "    # 在 m = 2 时, 跳出该递归。假设再递归一次，那么 H[0] = frozenset([2, 3, 5])，freqSet = frozenset([2, 3, 5]) ，没必要再计算 freqSet 与 H[0] 的关联规则了。\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m + 1)):\n",
    "        print('freqSet******************', len(freqSet), m + 1, freqSet, H, H[0])\n",
    "        # 生成 m+1 个长度的所有可能的 H 中的组合，假设 H = [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "        # 第一次递归调用时生成 [frozenset([2, 3]), frozenset([2, 5]), frozenset([3, 5])]\n",
    "        # 第二次 。。。没有第二次，递归条件判断时已经退出了\n",
    "        Hmp1 = apriori_gen(H, m+1)\n",
    "        # 返回可信度大于最小可信度的集合\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n",
    "        print('Hmp1=', Hmp1)\n",
    "        print('len(Hmp1)=', len(Hmp1), 'len(freqSet)=', len(freqSet))\n",
    "        # 计算可信度后，还有数据大于最小可信度的话，那么继续递归调用，否则跳出递归\n",
    "        if (len(Hmp1) > 1):\n",
    "            print('----------------------', Hmp1)\n",
    "            # print len(freqSet),  len(Hmp1[0]) + 1\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confData= frozenset({2, 3}) [frozenset({2}), frozenset({3})] frozenset({2}) frozenset({3})\n",
      "confData= frozenset({2, 3}) [frozenset({2}), frozenset({3})] frozenset({3}) frozenset({2})\n",
      "confData= frozenset({3, 5}) [frozenset({3}), frozenset({5})] frozenset({3}) frozenset({5})\n",
      "confData= frozenset({3, 5}) [frozenset({3}), frozenset({5})] frozenset({5}) frozenset({3})\n",
      "confData= frozenset({2, 5}) [frozenset({2}), frozenset({5})] frozenset({2}) frozenset({5})\n",
      "frozenset({5}) --> frozenset({2}) conf: 1.0\n",
      "confData= frozenset({2, 5}) [frozenset({2}), frozenset({5})] frozenset({5}) frozenset({2})\n",
      "frozenset({2}) --> frozenset({5}) conf: 1.0\n",
      "confData= frozenset({1, 3}) [frozenset({1}), frozenset({3})] frozenset({1}) frozenset({3})\n",
      "confData= frozenset({1, 3}) [frozenset({1}), frozenset({3})] frozenset({3}) frozenset({1})\n",
      "frozenset({1}) --> frozenset({3}) conf: 1.0\n",
      "freqSet****************** 3 2 frozenset({2, 3, 5}) [frozenset({2}), frozenset({3}), frozenset({5})] frozenset({2})\n",
      "confData= frozenset({2, 3, 5}) [frozenset({2, 3}), frozenset({2, 5}), frozenset({3, 5})] frozenset({2, 3}) frozenset({5})\n",
      "confData= frozenset({2, 3, 5}) [frozenset({2, 3}), frozenset({2, 5}), frozenset({3, 5})] frozenset({2, 5}) frozenset({3})\n",
      "confData= frozenset({2, 3, 5}) [frozenset({2, 3}), frozenset({2, 5}), frozenset({3, 5})] frozenset({3, 5}) frozenset({2})\n",
      "Hmp1= []\n",
      "len(Hmp1)= 0 len(freqSet)= 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0),\n",
       " (frozenset({1}), frozenset({3}), 1.0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L, supportdata = apriori(dataset, min_sup=0.5)\n",
    "rules = generateRules(L, supportdata, minConf=0.7)\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
